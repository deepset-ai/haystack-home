---
title: Haystack 2.20.0-rc1
description: Release notes for Haystack 2.20.0-rc1
toc: True
date: 2025-11-11
last_updated: 2025-11-11
tags: ["Release Notes"]
link: https://github.com/deepset-ai/haystack/releases/tag/v2.20.0-rc1
---

# Release Notes

## v2.21.0-rc0

### New Features

-   Added the <span class="title-ref">AzureOpenAIResponsesChatGenerator</span>, a new component that integrates Azure OpenAI's Responses API into Haystack. This unlocks several advanced capabilities from the Responses API:

    -   Allowing retrieval of concise summaries of the model's reasoning process.
    -   Allowing the use of native OpenAI or MCP tool formats, along with Haystack Tool objects and Toolset instances.

    Example with reasoning and web search tool: 
    ```python 
    from haystack.components.generators.chat import AzureOpenAIResponsesChatGenerator
    from haystack.dataclasses import ChatMessage  
    
    chat_generator = AzureOpenAIResponsesChatGenerator(azure_endpoint="https://example-resource.azure.openai.com/", azure_deployment="gpt-5-mini", generation_kwargs={"reasoning": {"effort": "low", "summary": "auto"}}, )  
    response = chat_generator.run(messages=[ChatMessage.from_user("What's Natural Language Processing?")] )

    print(response["replies"][0].text) 
    ```

-   Add an <span class="title-ref">extra</span> field to <span class="title-ref">ToolCall</span> and <span class="title-ref">ToolCallDelta</span> to store provider-specific information.

-   If logprobs are enabled in the generation kwargs, return logprobs in ChatMessage.meta for <span class="title-ref">OpenAIChatGenerator</span> and <span class="title-ref">OpenAIResponsesChatGenerator</span>.

-   Added the OpenAIResponsesChatGenerator, a new component that integrates OpenAI's Responses API into Haystack. This unlocks several advanced capabilities from the Responses API:

    -   Allowing retrieval of concise summaries of the model's reasoning process.
    -   Allowing the use of native OpenAI or MCP tool formats, along with Haystack Tool objects and Toolset instances.

    Example with reasoning and web search tool: 
    ```python 
    from haystack.components.generators.chat import OpenAIResponsesChatGenerator 
    from haystack.dataclasses import ChatMessage  
    chat_generator = OpenAIResponsesChatGenerator( model="o3-mini", generation_kwargs={ {"summary": "auto", "effort": "low"}     },tools=[{"type": "web_search"}] ) 
    response = chat_generator.run( messages=[ ChatMessage.from_user("What's a positive news story from today?")] )
    print(response["replies"][0].text) 
    ```

    Example with structured output: 
```python 
from pydantic import BaseModel 
from haystack.components.generators.chat import OpenAIResponsesChatGenerator 
from haystack.dataclasses import ChatMessage  

class WeatherInfo(BaseModel):     
     location: str 
     temperature: float 
     conditions: str  


chat_generator = OpenAIResponsesChatGenerator(model="gpt-5-mini", generation_kwargs={"text_format": WeatherInfo} ) 

response = chat_generator.run(messages=[ChatMessage.from_user("What's the weather in Paris?")] ) 
```

-   Updated our serialization and deserialization of PipelineSnapshots to work with pydantic BaseModels

-   Added async support to <span class="title-ref">SentenceWindowRetriever</span> with a new <span class="title-ref">run_async()</span> method, allowing the retriever to be used in async pipelines and workflows.

-   Added warm_up() method to all ChatGenerator components (OpenAIChatGenerator, AzureOpenAIChatGenerator, HuggingFaceAPIChatGenerator, HuggingFaceLocalChatGenerator, and FallbackChatGenerator) to properly initialize tools that require warm-up before pipeline execution. The warm_up() method is idempotent and follows the same pattern used in Agent and ToolInvoker components. This enables proper tool initialization in pipelines that use ChatGenerators with tools but without an Agent component.

-   The <span class="title-ref">AnswerBuilder</span> component now exposes a new parameter <span class="title-ref">return_only_referenced_documents</span> (default: True) that controls if only documents referenced in the <span class="title-ref">replies</span> are returned. Returned documents include two new fields in the <span class="title-ref">meta</span> dictionary:

    -   \`source_index\`: the 1-based index of the document in the input list

    \- \`referenced\`: a boolean value indicating if the document was referenced in the <span class="title-ref">replies</span> (only present if the <span class="title-ref">reference_pattern</span> parameter is provided). These additions make it easier to display references and other sources within a RAG pipeline.

### Enhancement Notes

-   Adds <span class="title-ref">generation_kwargs</span> to the <span class="title-ref">Agent</span> component, allowing for more fine-grained control at run-time over the chat generation.
-   Added a <span class="title-ref">revision</span> parameter to all Sentence Transformers embedder components (<span class="title-ref">SentenceTransformersDocumentEmbedder</span>, <span class="title-ref">SentenceTransformersTextEmbedder</span>, <span class="title-ref">SentenceTransformersSparseDocumentEmbedder</span>, and <span class="title-ref">SentenceTransformersSparseTextEmbedder</span>) to allow users to specify a specific model revision/version from the Hugging Face Hub. This enables pinning to a particular model version for reproducibility and stability.
-   Updated the components <span class="title-ref">Agent</span>, <span class="title-ref">LLMMetadataExtractor</span>, <span class="title-ref">LLMMessagesRouter</span>, and <span class="title-ref">LLMDocumentContentExtractor</span> to automatically call <span class="title-ref">self.warm_up()</span> at runtime if they have not been warmed up yet. This ensures that the components are ready for use without requiring an explicit warm-up call. This differs from previous behavior where the warm-up had to be manually invoked before using these components otherwise they would raise a <span class="title-ref">RuntimeError</span>.
-   Improve log-trace correlation for <span class="title-ref">DatadogTracer</span> by using the official <span class="title-ref">ddtrace.tracer.get_log_correlation_context()</span> method.
-   Improved Toolset warm-up architecture for better encapsulation. The base Toolset.warm_up() method now warms up all tools by default, while subclasses can override it to customize initialization (e.g., setting up shared resources instead of warming individual tools). The warm_up_tools() utility function has been simplified to delegate to Toolset.warm_up().

### Bug Fixes

-   Fix deserialization of state schema when it is None in Agent.from_dict.

-   Fixed type compatibility issue where passing <span class="title-ref">list\[Tool\]</span> to components with a <span class="title-ref">tools</span> parameter (such as <span class="title-ref">ToolInvoker</span>) caused static type checker errors. In version 2.19, the <span class="title-ref">ToolsType</span> was changed to <span class="title-ref">Union\[list\[Union\[Tool, Toolset\]\], Toolset\]</span> to support mixing Tools and Toolsets. However, due to Python's list invariance, <span class="title-ref">list\[Tool\]</span> was no longer considered compatible with <span class="title-ref">list\[Union\[Tool, Toolset\]\]</span>, breaking type checking for the common pattern of passing a list of Tool objects.

    The fix explicitly lists all valid type combinations in \`ToolsType\`: <span class="title-ref">Union\[list\[Tool\], list\[Toolset\], list\[Union\[Tool, Toolset\]\], Toolset\]</span>. This preserves backward compatibility for existing code while still supporting the new functionality of mixing Tools and Toolsets.

    Users who encountered type errors like "Argument of type 'list\[Tool\]' cannot be assigned to parameter 'tools'" should no longer see these errors after upgrading. No code changes are required on the user side.

-   When creating a pipeline snapshot we make sure to use \_deepcopy_with_exceptions when copying component inputs to avoid deep copies of items like components and tools since they often contain attributes that are not deep-copyable. For example, the LinkContentFetcher has httpx.Client as an attribute which throws an error if we try to deep copy it.

